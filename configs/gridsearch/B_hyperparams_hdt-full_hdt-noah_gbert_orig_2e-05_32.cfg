config_name	B_hyperparams_hdt-full_hdt-noah_gbert_orig_2e-05_32
name_train	train_hdt-full_gbert_orig
name_dev	dev_hdt_gbert_orig,dev_noah_gbert_orig
name_test	None
tagset_path	../datasets/tagset_upos.txt
max_sents_train	-1
max_sents_dev	-1
max_sents_test	-1
subset_selection	None
orig_dir_train	None
orig_dir_dev	None
T	128
orig_file_train	../datasets/train_HDT_UPOS.tsv
orig_file_dev	../datasets/dev_HDT_UPOS.tsv,../datasets/dev_NOAH_UPOS.tsv
orig_file_test	None
prepare_input_train	False
prepare_input_dev	False
prepare_input_test	False
reinit_train_each_seed	False
reinit_dev_each_seed	False
reinit_test_each_seed	False
subtoken_rep	None
tokenizer_name	deepset/gbert-base
use_sca_tokenizer	False
sca_sibling_weighting	None
noise_type	None
noise_lvl	0.0
noise_lvl	0.0
data_parent_dir	../data/
bert_name	deepset/gbert-base
plm_type	BertForMaskedLM
classifier_dropout	0.1
n_epochs	3
batch_size	32
learning_rate	2e-05
sanity_mod	1000
random_seeds	[12345, 23456, 34567, 45678, 56789]
