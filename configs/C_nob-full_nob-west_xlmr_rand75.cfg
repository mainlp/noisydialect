config_name	C_nob-full_nob-west_xlmr_rand75
name_train	train_ndt-nob-full_xlmr_rand75
name_dev	dev_ndt-nob_xlmr_orig,dev_lia-west_xlmr_orig
name_test	None
tagset_path	../datasets/tagset_upos.txt
max_sents_train	-1
max_sents_dev	-1
max_sents_test	-1
subset_selection	None
orig_dir_train	None
orig_dir_dev	None
T	128
orig_file_train	../datasets/train_NDT-NOB_UPOS.tsv
orig_file_dev	../datasets/dev_NDT-NOB_UPOS.tsv,../datasets/dev_LIA-west_UPOS.tsv
orig_file_test	None
prepare_input_train	True
prepare_input_dev	False
prepare_input_test	False
reinit_train_each_seed	True
reinit_dev_each_seed	False
reinit_test_each_seed	False
subtoken_rep	last
tokenizer_name	xlm-roberta-base
use_sca_tokenizer	False
sca_sibling_weighting	None
noise_type	add_random_noise
noise_lvl	0.75
data_parent_dir	../data/
bert_name	xlm-roberta-base
plm_type	XLMRobertaForMaskedLM
classifier_dropout	0.1
n_epochs	2
batch_size	32
learning_rate	2e-05
sanity_mod	1000
random_seeds	[12345, 23456, 34567, 45678, 56789]
